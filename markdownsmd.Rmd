---
title: "SDM_graph_markdown"
author: "Alícia Chimeno Sarabia"
date: "2024-03-23"
output:
  html_document:
    toc: true
    toc_float: true
    collapsed: false
editor_options: 
  chunk_output_type: console
---
```{r}
library(skimr)
library(ggplot2)
library(tidyverse)
library(dplyr)
library(stringi)
library(devtools)
```

```{r}
getwd()
setwd("/Users/ali/Downloads/dblp-to-csv-master")
#setwd("/Users/marcforto14/Desktop/dblp-to-csv-master")
```

# SECTION 1: papers <-> journals

Load:
```{r}
dblp_article<-read.csv("dblp_article.csv",sep=";",row.names =NULL, fileEncoding = "UTF-8",nrows=1000) # load
dblp_article_header<-read.csv("dblp_article_header.csv",sep=";",row.names =NULL, fileEncoding = "UTF-8") # load header
colnames(dblp_article)<-names(dblp_article_header) # put the header
```

Select:
Only want to keep: paper, authors, title, journal, volume, year, doi,
```{r}
names(dblp_article)
dblp_article$article.ID # id
dblp_article$author.string.. # string de autors
dblp_article$ee.string.. # doi number
dblp_article$pages.string # !!abanico de pages, no num of pages
dblp_article$volume.string
dblp_article$title.string
```

Function to count the pages:
```{r}
compute_pages <- function(page_range) {
  pages <- as.integer(unlist(strsplit(page_range, "-")))
  if (length(pages) == 1) {
    return(1)
  } else {
    return(pages[2] - pages[1] + 1)
  }
}

total_pages <- 0*c(1:nrow(dblp_article))

for (i in 1:nrow(dblp_article)) {
  total_pages[i] <- compute_pages(dblp_article$pages.string[i])
}
total_pages[999];dblp_article[999,24] #814-775 està bé
dblp_article$numpages<-total_pages
```

+Select:
```{r}
#filter columns
names(dblp_article)
dblp_article <- dblp_article[,c(1,2,13,16,30,34,35,36)]# id, author, doi, journal, pages, title, volume, year
```

- Split authors
- Create node df/csv of authors: :=authors_1. 
- Create csv/df relation authors-papers:= authors_paperID_1
```{r}
split_authors <- strsplit(dblp_article$author.string.., "\\|") # split els authors

authors_paperID_1 <- data.frame(
  id_paper = rep(dblp_article$article.ID, sapply(split_authors, length)),
  author = unlist(split_authors)
)

# if its the first author -> main 
mark_main_author <- function(group) {
  first_author <- group$author[1]
  group$main_author <- ifelse(startsWith(group$author, first_author), TRUE, FALSE)
  return(group)
}

authors_paperID_1 <- authors_paperID_1 %>%
  group_by(id_paper) %>%
  do(mark_main_author(.))

authors_1 <- unique(authors_paperID_1[,2])  # save authors names
```

Generate abstracts:
```{r}
generate_abstract <- function() {
  lorem_ipsum <- stri_rand_lipsum(1)  # Generate random Lorem Ipsum text
  return(lorem_ipsum)
}
dblp_article$abstract <- sapply(dblp_article$article.ID, function(x) generate_abstract())
```

+ Select/project. Create node df of papers (+metadata of papers)  :=papers_1
```{r}
names(dblp_article)
papers_1<- data.frame(
  id_paper=dblp_article$article.ID,
  paper_title=dblp_article$title.string,
  doi = dblp_article$ee.string..,
  abstract = dblp_article$abstract
)
```

# SECTION 2: papers <-> conferences INPROCEEDINGS

Dades dels *papers*:
```{r}
dblp_inproceedings<-read.csv("dblp_inproceedings.csv",sep=";",row.names =NULL, fileEncoding = "UTF-8",nrows=1000)
dblp_inproceedings_header<-read.csv("dblp_inproceedings_header.csv",sep=";",row.names =NULL, fileEncoding = "UTF-8")
colnames(dblp_inproceedings)<-names(dblp_inproceedings_header)
```

Count the pages:
```{r}
total_pages <- 0*c(1:nrow(dblp_inproceedings))

for (i in 1:nrow(dblp_inproceedings)) {
  total_pages[i] <- compute_pages(dblp_inproceedings$pages.string[i])
}
total_pages
dblp_inproceedings$numpages<-total_pages
```

Generate abstracts:
```{r}
dblp_inproceedings$abstract <- sapply(dblp_inproceedings$inproceedings.ID, function(x) generate_abstract())
```

```{r}
# explore
names(dblp_inproceedings)
dblp_inproceedings$author.string.. #author
dblp_inproceedings$title.string # titul dels papers
dblp_inproceedings$crossref.string.. # key 
dblp_inproceedings$inproceedings.ID # id dels papers
```

Create a dataframe with: id_paper-author (2 nodes 1 edge)
```{r}
split_authors <- strsplit(dblp_inproceedings$author.string.., "\\|") # split els authors

authors_paperID_2 <- data.frame(
  id_paper = rep(dblp_inproceedings$inproceedings.ID, sapply(split_authors, length)),
  author = unlist(split_authors)
)

authors_paperID_2 <- unique(authors_paperID_2) # remove duplicate rows (id_paper, author)

# if its the first author -> main 
mark_main_author <- function(group) {
  first_author <- group$author[1]
  group$main_author <- ifelse(startsWith(group$author, first_author), TRUE, FALSE)
  return(group)
}
authors_paperID_2 <- authors_paperID_2 %>%
  group_by(id_paper) %>%
  do(mark_main_author(.))

authors_2 <- unique(authors_paperID_2[,2])  # save only unique authors names
```

Node papers: idpaper-title-DOI-abstract
```{r}
papers_2<- data.frame(
  id_paper=dblp_inproceedings$inproceedings.ID,
  paper_title=dblp_inproceedings$title.string,
  doi = dblp_inproceedings$ee.string..,
  abstract = dblp_inproceedings$abstract,
  ref_conference = dblp_inproceedings$crossref.string..
)
```

## Combine and create CSV

```{r}
# Combine the two data frames using rbind
papers_df <- rbind(papers_1, papers_2)

authors_df <- rbind(authors_1, authors_2)
authors_df <- unique(authors_df)

authors_paperID_rel <- rbind(authors_paperID_1, authors_paperID_2)

write.csv(papers_df, "clean_datasets/papers_df.csv", row.names = FALSE) # df papers (node)
write.csv(authors_df, "clean_datasets/authors_df.csv", row.names = FALSE) # df authors (node)
write.csv(authors_df, "clean_datasets/authors_paperID_rel.csv", row.names = FALSE) # df authors papers (relation)
```

# Section 4 : papers <-> conferences PROCEEDINGS
Dades de les CONFERENCES

<details>
<summary>conferences</summary>
```{r}
dblp_proceedings<-read.csv("dblp_proceedings.csv",sep=";",row.names =NULL, encoding = "latin1",nrows=100000)
dblp_proceedings_header<-read.csv("dblp_proceedings_header.csv",sep=";",row.names =NULL, encoding = "latin1")
colnames(dblp_proceedings)<-names(dblp_proceedings_header)
```

```{r}
#explore
colnames(dblp_proceedings)
dblp_proceedings$title.string # conference / workshop complete 
dblp_proceedings$booktitle.string # conference / workshop name 
dblp_proceedings$key.string # key
```


```{r}
conference_split <- strsplit(dblp_proceedings$title.string, ", ")
conference_split[[945]] # example of entry
conference_name <- sapply(conference_split, function(x) paste(x[1], collapse = ", "))

detect_location <- function(entry) {
  location <- entry[nchar(entry) < 20 & !grepl("\\d", entry)] # Select entries shorter than 20 characters and without any number
  location <- paste(location, collapse = ", ") # Combine into a single string
  return(location)
}
locations <- sapply(conference_split, detect_location)
conference_title <- sub(".*?((?:Conference|Workshop).*?$)", "\\1", conference_name)

```


```{r}
# Extract the edition of each conference / workshop
extract_ordinals <- function(names_list) {
  # Regular expression pattern to match ordinal numbers up to "30th"
  ordinal_pattern <- "\\b(?:[1-9]1?st|[1-9]2?nd|[1-9]3?rd|[4-9][0-9]?th|(1[0-9]|2[0-9]|3[0-9]|99)th|First|Second|Third|Fourth|Fifth|Sixth|Seventh|Eighth|Ninth|Tenth|Eleventh|Twelfth|Thirteenth|Fourteenth|Fifteenth|Sixteenth|Seventeenth|Eighteenth|Nineteenth|Twentieth|Twenty-first|Twenty-second|Twenty-third|Twenty-fourth|Twenty-fifth|Twenty-sixth|Twenty-seventh|Twenty-eighth|Twenty-ninth|Thirtieth|Thirty-first|Thirty-second|Thirty-third|Thirty-fourth|Thirty-fifth|Thirty-sixth|Thirty-seventh|Thirty-eighth|Thirty-ninth|Fortieth|Forty-first|Forty-second|Forty-third|Forty-fourth|Forty-fifth|Forty-sixth|Forty-seventh|Forty-eighth|Forty-ninth|Fiftieth|Fifty-first|Fifty-second|Fifty-third|Fifty-fourth|Fifty-fifth|Fifty-sixth|Fifty-seventh|Fifty-eighth|Fifty-ninth|Sixtieth|Sixty-first|Sixty-second|Sixty-third|Sixty-fourth|Sixty-fifth|Sixty-sixth|Sixty-seventh|Sixty-eighth|Sixty-ninth|Seventieth|Seventy-first|Seventy-second|Seventy-third|Seventy-fourth|Seventy-fifth|Seventy-sixth|Seventy-seventh|Seventy-eighth|Seventy-ninth|Eightieth|Eighty-first|Eighty-second|Eighty-third|Eighty-fourth|Eighty-fifth|Eighty-sixth|Eighty-seventh|Eighty-eighth|Eighty-ninth|Ninetieth|Ninety-first|Ninety-second|Ninety-third|Ninety-fourth|Ninety-fifth|Ninety-sixth|Ninety-seventh|Ninety-eighth|Ninety-ninth)\\b"
  
  # Extract ordinal numbers from each entry
  extracted_ordinals <- regmatches(names_list, gregexpr(ordinal_pattern, names_list))
  
  # Create a vector to store the EDITIONS results
  result <- character(length(names_list))
  
  # Loop through each entry to assign ordinal numbers or NA
  for (i in seq_along(names_list)) {
    if (length(extracted_ordinals[[i]]) == 1) {# if > 1, combination of conferences -> too dificult to detect
      ordinal_text <- extracted_ordinals[[i]]
      # Check if the ordinal text already follows the "...th" pattern
      if (grepl("\\b(?:\\d+st|\\d+nd|\\d+rd|\\d+th)", ordinal_text)) {
        result[i] <- ordinal_text
      } else {
        # Extract the numeric value from the ordinal text
        numeric_value <- switch(ordinal_text,
                                "First" = 1,
                                "Second" = 2,
                                "Third" = 3,
                                "Fourth" = 4,
                                "Fifth" = 5,
                                "Sixth" = 6,
                                "Seventh" = 7,
                                "Eighth" = 8,
                                "Ninth" = 9,
                                "Tenth" = 10,
                                "Eleventh" = 11,
                                "Twelfth" = 12,
                                "Thirteenth" = 13,
                                "Fourteenth" = 14,
                                "Fifteenth" = 15,
                                "Sixteenth" = 16,
                                "Seventeenth" = 17,
                                "Eighteenth" = 18,
                                "Nineteenth" = 19,
                                "Twentieth" = 20,
                                "Twenty-first" = 21,
                                "Twenty-second" = 22,
                                "Twenty-third" = 23,
                                "Twenty-fourth" = 24,
                                "Twenty-fifth" = 25,
                                "Twenty-sixth" = 26,
                                "Twenty-seventh" = 27,
                                "Twenty-eighth" = 28,
                                "Twenty-ninth" = 29,
                                "Thirtieth" = 30,
                                "Thirty-first" = 31,
                                "Thirty-second" = 32,
                                "Thirty-third" = 33,
                                "Thirty-fourth" = 34,
                                "Thirty-fifth" = 35,
                                "Thirty-sixth" = 36,
                                "Thirty-seventh" = 37,
                                "Thirty-eighth" = 38,
                                "Thirty-ninth" = 39,
                                "Fortieth" = 40,
                                "Forty-first" = 41,
                                "Forty-second" = 42,
                                "Forty-third" = 43,
                                "Forty-fourth" = 44,
                                "Forty-fifth" = 45,
                                "Forty-sixth" = 46,
                                "Forty-seventh" = 47,
                                "Forty-eighth" = 48,
                                "Forty-ninth" = 49,
                                "Fiftieth" = 50,
                                "Fifty-first" = 51,
                                "Fifty-second" = 52,
                                "Fifty-third" = 53,
                                "Fifty-fourth" = 54,
                                "Fifty-fifth" = 55,
                                "Fifty-sixth" = 56,
                                "Fifty-seventh" = 57,
                                "Fifty-eighth" = 58,
                                "Fifty-ninth" = 59,
                                "Sixtieth" = 60,
                                "Sixty-first" = 61,
                                "Sixty-second" = 62,
                                "Sixty-third" = 63,
                                "Sixty-fourth" = 64,
                                "Sixty-fifth" = 65,
                                "Sixty-sixth" = 66,
                                "Sixty-seventh" = 67,
                                "Sixty-eighth" = 68,
                                "Sixty-ninth" = 69,
                                "Seventieth" = 70,
                                "Seventy-first" = 71,
                                "Seventy-second" = 72,
                                "Seventy-third" = 73,
                                "Seventy-fourth" = 74,
                                "Seventy-fifth" = 75,
                                "Seventy-sixth" = 76,
                                "Seventy-seventh" = 77,
                                "Seventy-eighth" = 78,
                                "Seventy-ninth" = 79,
                                "Eightieth" = 80,
                                "Eighty-first" = 81,
                                "Eighty-second" = 82,
                                "Eighty-third" = 83,
                                "Eighty-fourth" = 84,
                                "Eighty-fifth" = 85,
                                "Eighty-sixth" = 86,
                                "Eighty-seventh" = 87,
                                "Eighty-eighth" = 88,
                                "Eighty-ninth" = 89,
                                "Ninetieth" = 90,
                                "Ninety-first" = 91,
                                "Ninety-second" = 92,
                                "Ninety-third" = 93,
                                "Ninety-fourth" = 94,
                                "Ninety-fifth" = 95,
                                "Ninety-sixth" = 96,
                                "Ninety-seventh" = 97,
                                "Ninety-eighth" = 98,
                                "Ninety-ninth" = 99)
        result[i] <- paste0(numeric_value, "th")
      }
    } else {
      result[i] <- NA
    }
  }
  return(result)
}
conference_edition <- extract_ordinals(conference_name)
table(conference_edition)
```


```{r}
conference_df <- data.frame(
  conference_complete=dblp_proceedings$title.string,
  acronym=dblp_proceedings$booktitle.string,
  ref=dblp_proceedings$key.string,
  conference_name=conference_name,
  conference_title = conference_title,
  conference_edition=conference_edition,
  location = locations,
  year=dblp_proceedings$year.int
)
conference_df
```

</details>

# Section 5: topics
Amb Python 

```{r}
dblp_topics<-read.csv("data_topics.csv",row.names =NULL, encoding = "latin1",header=TRUE)
dblp_topics
```



# Section 6: cites
We will assume that if two papers have the 1st same keyword (the most probable) , then their content is related. 
For each paper we will assign a random number - from 0-5 that will indicate the number of cites this paper has. 

```{r}
cites_df <- data.frame(
  id_paper=dblp_topics["id_paper"],
  keyword_1=dblp_topics["keyword_1"]
)
cites_df
cites_df$ncites <- sample(0:5, nrow(cites_df), replace = TRUE)
names(cites_df)
```

We will group for each keaword 
agrupem per cada keyword_1 -> 

```{r}
df_list <- split(cites_df, cites_df$keyword_1)
names(df_list)
df_list$AI
```


```{r}
names(df_list)
df_list[c(2:15)]
names(df_list[c(2:15)])
for (topic in names(df_list[c(2:15)])) {
  # Set 'cites' column to NA
  df_list[[topic]]$cites <- NA
  
  # Iterate over each row of the data frame
  for (i in 1:nrow(df_list[[topic]])) {
    # Generate random numbers
    id_paper <- df_list[[topic]][i, "id_paper"]
    ncites <- df_list[[topic]][i, "ncites"]
    random_numbers <- sample(df_list[[topic]]$id_paper, ncites, replace = FALSE)
    
    # Save random citations into the 'cites' column as a single string
    df_list[[topic]][i, "cites"] <- paste(random_numbers, collapse = ",")
  }
  
  # Separate the 'cites' column into five separate columns
  df_list[[topic]] <- separate(df_list[[topic]], cites, into = paste0("cites_", 1:5), sep = ",", fill = "right")
}

df_list[c(2:15)]

```

Find the top 3 most cited papers of each conference.

```{r}
df_list

# conference list 
```


# Section 7: reviewers 

