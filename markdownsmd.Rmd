---
title: "SDM_graph_markdown"
author: "Alícia Chimeno Sarabia"
date: "2024-03-23"
output:
  html_document:
    toc: true
    toc_float: true
    collapsed: false
editor_options: 
  chunk_output_type: console
---
libraries
```{r}
library(skimr)
library(ggplot2)
library(tidyverse)
library(dplyr)
library(stringi)
library(devtools)
```

load
```{r}
getwd()
setwd("/Users/ali/Downloads/dblp-to-csv-master")
#setwd("/Users/marcforto14/Desktop/dblp-to-csv-master")
```

# SECTION 1: papers <-> journals

Load:
```{r}
dblp_article<-read.csv("dblp_article.csv",sep=";",row.names =NULL, fileEncoding = "UTF-8",nrows=1000) # load
dblp_article_header<-read.csv("dblp_article_header.csv",sep=";",row.names =NULL, fileEncoding = "UTF-8") # load header
colnames(dblp_article)<-names(dblp_article_header) # put the header
```


Function to count the pages:
```{r}
compute_pages <- function(page_range) {
  pages <- as.integer(unlist(strsplit(page_range, "-")))
  if (length(pages) == 1) {
    return(1)
  } else {
    return(pages[2] - pages[1] + 1)
  }
}

total_pages <- 0*c(1:nrow(dblp_article))

for (i in 1:nrow(dblp_article)) {
  total_pages[i] <- compute_pages(dblp_article$pages.string[i])
}
#total_pages[999];dblp_article[999,24] #814-775 està bé
dblp_article$numpages<-total_pages
```

Filtrem:
```{r}
Edge_paper_volumes_try1 <- data.frame(
  id_paper = dblp_article$article.ID,
  id_volume = paste(dblp_article$volume.string, dblp_article$journal.string, sep = " "),
  volume = dblp_article$volume.string,
  journal=dblp_article$journal.string
)
keep_repeated_values <- function(lst) {
  counts <- table(lst)
  repeated_values <- names(counts[counts >= 2])
  return(repeated_values)
}
vol<-keep_repeated_values(Edge_paper_volumes_try1$id_volume) # volumes that have 2 or more papers
pap_in_vol<-Edge_paper_volumes_try1$id_paper[Edge_paper_volumes_try1$id_volume %in% vol]
Edge_paper_volumes_try1[Edge_paper_volumes_try1$id_paper %in%pap_in_vol,]
```

Node_volume
```{r}
Node_volume<-data.frame(
  id_volume=vol)
write.csv(Node_volume, "Node_volume.csv", row.names = FALSE) 

```

Edge_paper_volumes
```{r}
Edge_paper_volumes <- Edge_paper_volumes_try1[Edge_paper_volumes_try1$id_volume %in% vol,c(1,2)]
write.csv(Edge_paper_volumes, "Edge_paper_volumes.csv", row.names = FALSE) 

```

dblp_article_filtered
```{r}
dblp_article_filtered<-dblp_article[dblp_article$article.ID %in% pap_in_vol,]
```


Edge_volume_journal:
```{r}
Edge_volume_journal <- data.frame(
  id_volume = Edge_paper_volumes_try1$id_volume,
  journal = Edge_paper_volumes_try1$journal
)
Edge_volume_journal
write.csv(Edge_volume_journal, "Edge_volume_journal.csv", row.names = FALSE)
```

Node_journals:
```{r}
Node_journals <- unique(Edge_volume_journal[2])
write.csv(Node_journals, "Node_journals.csv", row.names = FALSE) 
```


Edge_papers_author_1
```{r}

split_authors <- strsplit(dblp_article_filtered$author.string.., "\\|") # split els authors

Edge_papers_author_1 <- data.frame(
  id_paper = rep(dblp_article_filtered$article.ID, sapply(split_authors, length)),
  author = unlist(split_authors)
)

# if its the first author -> main 
mark_main_author <- function(group) {
  first_author <- group$author[1]
  group$main_author <- ifelse(startsWith(group$author, first_author), TRUE, FALSE)
  return(group)
}

Edge_papers_author_1 <- Edge_papers_author_1 %>%
  group_by(id_paper) %>%
  do(mark_main_author(.))

Edge_papers_author_1 # edge amb property. de la relation 
```

Node_authors_1
```{r}
Node_authors_1 <- unique(Edge_papers_author_1[,2])  # save authors names
```

Generate abstracts:
```{r}
generate_abstract <- function() {
  lorem_ipsum <- stri_rand_lipsum(1)  # Generate random Lorem Ipsum text
  return(lorem_ipsum)
}
dblp_article_filtered$abstract <- sapply(dblp_article_filtered$article.ID, function(x) generate_abstract())
```

Node_papers_1
```{r}
names(dblp_article_filtered)
Node_papers_1<- data.frame(
  id_paper=dblp_article_filtered$article.ID,
  paper_title=dblp_article_filtered$title.string,
  doi = dblp_article_filtered$ee.string..,
  abstract = dblp_article_filtered$abstract
)
Node_papers_1
```


# SECTION 2: papers <-> conferences INPROCEEDINGS

Dades dels *papers*:
```{r}
dblp_inproceedings<-read.csv("dblp_inproceedings.csv",sep=";",row.names =NULL, fileEncoding = "UTF-8",nrows=1000)
dblp_inproceedings_header<-read.csv("dblp_inproceedings_header.csv",sep=";",row.names =NULL, fileEncoding = "UTF-8")
colnames(dblp_inproceedings)<-names(dblp_inproceedings_header)
```

Count the pages:
```{r}
total_pages <- 0*c(1:nrow(dblp_inproceedings))

for (i in 1:nrow(dblp_inproceedings)) {
  total_pages[i] <- compute_pages(dblp_inproceedings$pages.string[i])
}
total_pages
dblp_inproceedings$numpages<-total_pages
```

Generate abstracts:
```{r}
dblp_inproceedings$abstract <- sapply(dblp_inproceedings$inproceedings.ID, function(x) generate_abstract())
```

```{r}
# explore
names(dblp_inproceedings)
dblp_inproceedings$author.string.. #author
dblp_inproceedings$title.string # titul dels papers
dblp_inproceedings$crossref.string.. # key 
dblp_inproceedings$inproceedings.ID # id dels papers
```

Edge_papers_author_2
```{r}
split_authors <- strsplit(dblp_inproceedings$author.string.., "\\|") # split els authors

Edge_papers_author_2 <- data.frame(
  id_paper = rep(dblp_inproceedings$inproceedings.ID, sapply(split_authors, length)),
  author = unlist(split_authors)
)

Edge_papers_author_2 <- unique(Edge_papers_author_2) # remove duplicate rows (id_paper, author)

# if its the first author -> main 
mark_main_author <- function(group) {
  first_author <- group$author[1]
  group$main_author <- ifelse(startsWith(group$author, first_author), TRUE, FALSE)
  return(group)
}
Edge_papers_author_2 <- Edge_papers_author_2 %>%
  group_by(id_paper) %>%
  do(mark_main_author(.))
```

Node_authors_2
```{r}
Node_authors_2 <- unique(Edge_papers_author_2[,2])  # save only unique authors names
```

Node papers: idpaper-title-DOI-abstract
```{r}
Node_papers_2<- data.frame(
  id_paper=dblp_inproceedings$inproceedings.ID,
  paper_title=dblp_inproceedings$title.string,
  doi = dblp_inproceedings$ee.string..,
  abstract = dblp_inproceedings$abstract
)
```

## Combine and create CSV

```{r}
# Combine the two data frames using rbind
Node_paper <- rbind(Node_papers_1, Node_papers_2)
Node_paper
names(Node_paper)
Node_author <- rbind(Node_authors_1, Node_authors_2)
Node_author <- unique(Node_author)
Node_author
skim(Node_author)

Edge_papers_author <- rbind(Edge_papers_author_1, Edge_papers_author_2)

write.csv(Node_paper, "Node_paper.csv", row.names = FALSE) # df papers (node)
write.csv(Node_author, "Node_author.csv", row.names = FALSE) # df authors (node)
write.csv(Edge_papers_author, "Edge_papers_author.csv", row.names = FALSE) # df authors papers (relation)
```

# Section 4 : papers <-> conferences PROCEEDINGS
Dades de les CONFERENCES

```{r}
dblp_proceedings<-read.csv("dblp_proceedings.csv",sep=";",row.names =NULL, encoding = "latin1",nrows=100000)
dblp_proceedings_header<-read.csv("dblp_proceedings_header.csv",sep=";",row.names =NULL, encoding = "latin1")
colnames(dblp_proceedings)<-names(dblp_proceedings_header)
```

```{r}
#explore
colnames(dblp_proceedings)
dblp_proceedings$title.string # conference / workshop complete 
dblp_proceedings$booktitle.string # conference / workshop name 
dblp_proceedings$key.string # key
```


```{r}
conference_split <- strsplit(dblp_proceedings$title.string, ", ")
conference_split[[945]] # example of entry
conference_name <- sapply(conference_split, function(x) paste(x[1], collapse = ", "))

detect_location <- function(entry) {
  location <- entry[nchar(entry) < 20 & !grepl("\\d", entry)] # Select entries shorter than 20 characters and without any number
  location <- paste(location, collapse = ", ") # Combine into a single string
  return(location)
}
locations <- sapply(conference_split, detect_location)
conference_title <- sub(".*?((?:Conference|Workshop).*?$)", "\\1", conference_name)

```


```{r}
# Extract the edition of each conference / workshop
extract_ordinals <- function(names_list) {
  # Regular expression pattern to match ordinal numbers up to "30th"
  ordinal_pattern <- "\\b(?:[1-9]1?st|[1-9]2?nd|[1-9]3?rd|[4-9][0-9]?th|(1[0-9]|2[0-9]|3[0-9]|99)th|First|Second|Third|Fourth|Fifth|Sixth|Seventh|Eighth|Ninth|Tenth|Eleventh|Twelfth|Thirteenth|Fourteenth|Fifteenth|Sixteenth|Seventeenth|Eighteenth|Nineteenth|Twentieth|Twenty-first|Twenty-second|Twenty-third|Twenty-fourth|Twenty-fifth|Twenty-sixth|Twenty-seventh|Twenty-eighth|Twenty-ninth|Thirtieth|Thirty-first|Thirty-second|Thirty-third|Thirty-fourth|Thirty-fifth|Thirty-sixth|Thirty-seventh|Thirty-eighth|Thirty-ninth|Fortieth|Forty-first|Forty-second|Forty-third|Forty-fourth|Forty-fifth|Forty-sixth|Forty-seventh|Forty-eighth|Forty-ninth|Fiftieth|Fifty-first|Fifty-second|Fifty-third|Fifty-fourth|Fifty-fifth|Fifty-sixth|Fifty-seventh|Fifty-eighth|Fifty-ninth|Sixtieth|Sixty-first|Sixty-second|Sixty-third|Sixty-fourth|Sixty-fifth|Sixty-sixth|Sixty-seventh|Sixty-eighth|Sixty-ninth|Seventieth|Seventy-first|Seventy-second|Seventy-third|Seventy-fourth|Seventy-fifth|Seventy-sixth|Seventy-seventh|Seventy-eighth|Seventy-ninth|Eightieth|Eighty-first|Eighty-second|Eighty-third|Eighty-fourth|Eighty-fifth|Eighty-sixth|Eighty-seventh|Eighty-eighth|Eighty-ninth|Ninetieth|Ninety-first|Ninety-second|Ninety-third|Ninety-fourth|Ninety-fifth|Ninety-sixth|Ninety-seventh|Ninety-eighth|Ninety-ninth)\\b"
  
  # Extract ordinal numbers from each entry
  extracted_ordinals <- regmatches(names_list, gregexpr(ordinal_pattern, names_list))
  
  # Create a vector to store the EDITIONS results
  result <- character(length(names_list))
  
  # Loop through each entry to assign ordinal numbers or NA
  for (i in seq_along(names_list)) {
    if (length(extracted_ordinals[[i]]) == 1) {# if > 1, combination of conferences -> too dificult to detect
      ordinal_text <- extracted_ordinals[[i]]
      # Check if the ordinal text already follows the "...th" pattern
      if (grepl("\\b(?:\\d+st|\\d+nd|\\d+rd|\\d+th)", ordinal_text)) {
        result[i] <- ordinal_text
      } else {
        # Extract the numeric value from the ordinal text
        numeric_value <- switch(ordinal_text,
                                "First" = 1,
                                "Second" = 2,
                                "Third" = 3,
                                "Fourth" = 4,
                                "Fifth" = 5,
                                "Sixth" = 6,
                                "Seventh" = 7,
                                "Eighth" = 8,
                                "Ninth" = 9,
                                "Tenth" = 10,
                                "Eleventh" = 11,
                                "Twelfth" = 12,
                                "Thirteenth" = 13,
                                "Fourteenth" = 14,
                                "Fifteenth" = 15,
                                "Sixteenth" = 16,
                                "Seventeenth" = 17,
                                "Eighteenth" = 18,
                                "Nineteenth" = 19,
                                "Twentieth" = 20,
                                "Twenty-first" = 21,
                                "Twenty-second" = 22,
                                "Twenty-third" = 23,
                                "Twenty-fourth" = 24,
                                "Twenty-fifth" = 25,
                                "Twenty-sixth" = 26,
                                "Twenty-seventh" = 27,
                                "Twenty-eighth" = 28,
                                "Twenty-ninth" = 29,
                                "Thirtieth" = 30,
                                "Thirty-first" = 31,
                                "Thirty-second" = 32,
                                "Thirty-third" = 33,
                                "Thirty-fourth" = 34,
                                "Thirty-fifth" = 35,
                                "Thirty-sixth" = 36,
                                "Thirty-seventh" = 37,
                                "Thirty-eighth" = 38,
                                "Thirty-ninth" = 39,
                                "Fortieth" = 40,
                                "Forty-first" = 41,
                                "Forty-second" = 42,
                                "Forty-third" = 43,
                                "Forty-fourth" = 44,
                                "Forty-fifth" = 45,
                                "Forty-sixth" = 46,
                                "Forty-seventh" = 47,
                                "Forty-eighth" = 48,
                                "Forty-ninth" = 49,
                                "Fiftieth" = 50,
                                "Fifty-first" = 51,
                                "Fifty-second" = 52,
                                "Fifty-third" = 53,
                                "Fifty-fourth" = 54,
                                "Fifty-fifth" = 55,
                                "Fifty-sixth" = 56,
                                "Fifty-seventh" = 57,
                                "Fifty-eighth" = 58,
                                "Fifty-ninth" = 59,
                                "Sixtieth" = 60,
                                "Sixty-first" = 61,
                                "Sixty-second" = 62,
                                "Sixty-third" = 63,
                                "Sixty-fourth" = 64,
                                "Sixty-fifth" = 65,
                                "Sixty-sixth" = 66,
                                "Sixty-seventh" = 67,
                                "Sixty-eighth" = 68,
                                "Sixty-ninth" = 69,
                                "Seventieth" = 70,
                                "Seventy-first" = 71,
                                "Seventy-second" = 72,
                                "Seventy-third" = 73,
                                "Seventy-fourth" = 74,
                                "Seventy-fifth" = 75,
                                "Seventy-sixth" = 76,
                                "Seventy-seventh" = 77,
                                "Seventy-eighth" = 78,
                                "Seventy-ninth" = 79,
                                "Eightieth" = 80,
                                "Eighty-first" = 81,
                                "Eighty-second" = 82,
                                "Eighty-third" = 83,
                                "Eighty-fourth" = 84,
                                "Eighty-fifth" = 85,
                                "Eighty-sixth" = 86,
                                "Eighty-seventh" = 87,
                                "Eighty-eighth" = 88,
                                "Eighty-ninth" = 89,
                                "Ninetieth" = 90,
                                "Ninety-first" = 91,
                                "Ninety-second" = 92,
                                "Ninety-third" = 93,
                                "Ninety-fourth" = 94,
                                "Ninety-fifth" = 95,
                                "Ninety-sixth" = 96,
                                "Ninety-seventh" = 97,
                                "Ninety-eighth" = 98,
                                "Ninety-ninth" = 99)
        result[i] <- paste0(numeric_value, "th")
      }
    } else {
      result[i] <- NA
    }
  }
  return(result)
}
conference_edition <- extract_ordinals(conference_name)
#table(conference_edition)
names(dblp_proceedings)
unique(dblp_proceedings$booktitle.string)
```

union edition and papers
```{r}
left_join_df <- left_join(Node_paper, conference_df, by = c("crossref.string.."="ref"))
names(Edge_papers_edition)

unique(Edge_papers_edition$ref_conf)
```


Node_edition
```{r}
Node_edition_try <- data.frame(
  ref_edition=dblp_proceedings$key.string,
  editio_complete=dblp_proceedings$title.string,
  acronym=dblp_proceedings$booktitle.string, #acronym conference
  conference_name=conference_name,
  conference_title = conference_title,
  conference_edition=conference_edition,
  location = locations,
  year=dblp_proceedings$year.int
)

Node_edition<- data.frame(
  ref_edition=dblp_proceedings$key.string,
  edition=dblp_proceedings$title.string,
  edition_num=conference_edition,
  location = locations,
  year=dblp_proceedings$year.int
)

write.csv(Node_edition, "Node_edition.csv", row.names = FALSE) 

names(Node_edition)
```


Edge_edition_conference
```{r}

Edge_edition_conference<- data.frame(
  ref_edition=dblp_proceedings$key.string,
  conference=dblp_proceedings$booktitle.string #acronym conference
)


```

Node_conference
```{r}

Node_conference<- data.frame(
  unique(dblp_proceedings$booktitle.string)
  
)
```


Edge_papers_edition
```{r}
Edge_papers_edition_all<- data.frame(
  id_paper=dblp_inproceedings$inproceedings.ID,
  ref_conf=dblp_inproceedings$crossref.string..
)
papers_1$id_paper

```






# Section 5: topics
Amb Python 
```{r}
setwd("/Users/ali/Desktop/MASTER/Semestre 2/SDM/lab/PropertyGraph/Sense nom/PropertyGraphs_SDM/data")
dblp_topics<-read.csv("data_topics.csv",row.names =NULL, encoding = "latin1",header=TRUE)
```

Edge_papers_keywords
```{r}
names(dblp_topics)
Edge_papers_keywords<-dblp_topics[,c(1,3:5)]
```

Node_keywords
```{r}
Node_keywords <- unique(Edge_papers_keywords[,2])
Node_keywords

nsoe <- pivot_longer(Edge_papers_keywords, cols = -id_paper, values_to = "cites_value")
```

Edge_keywords (altre format)
```{r}
Edge_keywords<-nsoe[,c(1,3)]
Edge_keywords
```



# Section 6: cites
We will assume that if two papers have the 1st same keyword (the most probable) , then their content is related. 
For each paper we will assign a random number - from 0-5 that will indicate the number of cites this paper has. 

```{r}
cites_df <- data.frame(
  id_paper=dblp_topics["id_paper"],
  keyword_1=dblp_topics["keyword_1"]
)
cites_df
cites_df$ncites <- sample(0:5, nrow(cites_df), replace = TRUE)
names(cites_df)
```

We will group for each keaword 
agrupem per cada keyword_1 -> 

```{r}
df_list <- split(cites_df, cites_df$keyword_1)
names(df_list)
df_list$AI
```


```{r}
names(df_list)
df_list[c(1:14)]
names(df_list[c(1:14)])
for (topic in names(df_list[c(1:14)])) {
  # Set 'cites' column to NA
  df_list[[topic]]$cites <- NA
  
  # Iterate over each row of the data frame
  for (i in 1:nrow(df_list[[topic]])) {
    # Generate random numbers
    id_paper <- df_list[[topic]][i, "id_paper"]
    ncites <- df_list[[topic]][i, "ncites"]
    random_numbers <- sample(df_list[[topic]]$id_paper, ncites, replace = FALSE)
    
    # Save random citations into the 'cites' column as a single string
    df_list[[topic]][i, "cites"] <- paste(random_numbers, collapse = ",")
  }
  
  # Separate the 'cites' column into five separate columns
  df_list[[topic]] <- separate(df_list[[topic]], cites, into = paste0("cites_", 1:5), sep = ",", fill = "right")
}

df_list[c(1:14)]
names(df_list[c(1:14)])

```

merge all lists
```{r}
merged_df <- Reduce(function(x, y) merge(x, y, by=c("id_paper","keyword_1","ncites","cites_1","cites_2","cites_3","cites_4","cites_5"), all = TRUE), df_list[1:14])

```

cannot cite himself , convertim en NA quan es cita a ell mateix
```{r}

#  convertir en NA el num que es ell mateix
merged_df$cites_1 <- ifelse(merged_df$id_paper == merged_df$cites_1, NA, merged_df$cites_1)
merged_df$cites_2 <- ifelse(merged_df$id_paper == merged_df$cites_2 , NA, merged_df$cites_2)
merged_df$cites_3 <- ifelse(merged_df$id_paper == merged_df$cites_3, NA, merged_df$cites_3)
merged_df$cites_4 <- ifelse(merged_df$id_paper == merged_df$cites_4, NA, merged_df$cites_4)
merged_df$cites_5 <- ifelse(merged_df$id_paper == merged_df$cites_5, NA, merged_df$cites_5)

# comprovem
merged_df_wrong <- merged_df[merged_df$id_paper == merged_df$cites_1 |
                             merged_df$id_paper == merged_df$cites_2 |
                             merged_df$id_paper == merged_df$cites_3 |
                             merged_df$id_paper == merged_df$cites_4 |
                             merged_df$id_paper == merged_df$cites_5, ]

merged_df_wrong[complete.cases(merged_df_wrong), ]

```

```{r}
Edge_cites_cols<-merged_df[,c(1,4:8)]
Edge_cites_cols
```

Nose si s'ha de fer aquest format:
```{r}

long_df <- pivot_longer(Edge_cites_cols, cols = -id_paper, names_to = "cites_number", values_to = "cites_value")
long_df <- long_df[complete.cases(long_df$cites_value), ]
Edge_cites<-long_df[,c(1,3)]
Edge_cites
```


# Section 7: reviews

for each paper assign 3 authors reviewers ? 
```{r}
Node_author

Node_paper$id_paper
set.seed(123)
sample_data1 <- sample(Node_author$author, nrow(Node_paper), replace = TRUE)
set.seed(124)
sample_data2 <- sample(Node_author$author, nrow(Node_paper), replace = TRUE)
set.seed(125)
sample_data3 <- sample(Node_author$author, nrow(Node_paper), replace = TRUE)
```

Node paper-author juntem per comprovar q un author no pot fer review del seu paper: 
```{r}

Edge_papers_author

dataf<-data.frame(
  idpap=Node_paper$id_paper,
  author1=sample_data1,
  author2=sample_data2,
  author3=sample_data3
)
dataf # per cada id he creat 3 autors relacionats

left_join_df<- left_join(Edge_papers_author,dataf, by = c("id_paper"="idpap"))
# mirar que no reviewing el seu paper: 

left_join_df[left_join_df$author == left_join_df$author1, ] # exemple malament

left_join_df$author1 <- ifelse(left_join_df$author == left_join_df$author1, NA, left_join_df$author1)
left_join_df$author2 <- ifelse(left_join_df$author == left_join_df$author2 , NA, left_join_df$author2)
left_join_df$author3 <- ifelse(left_join_df$author == left_join_df$author3, NA, left_join_df$author3)

left_join_df


```

