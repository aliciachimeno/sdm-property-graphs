#explore
colnames(dblp_proceedings)
dblp_proceedings$title.string # conference / workshop complete
dblp_proceedings$booktitle.string # conference / workshop name
dblp_proceedings$key.string # key
# Chunk 26
conference_split <- strsplit(dblp_proceedings$title.string, ", ")
conference_split[[945]] # example of entry
conference_name <- sapply(conference_split, function(x) paste(x[1], collapse = ", "))
detect_location <- function(entry) {
location <- entry[nchar(entry) < 20 & !grepl("\\d", entry)] # Select entries shorter than 20 characters and without any number
location <- paste(location, collapse = ", ") # Combine into a single string
return(location)
}
locations <- sapply(conference_split, detect_location)
conference_title <- sub(".*?((?:Conference|Workshop).*?$)", "\\1", conference_name)
# Chunk 27
# Extract the edition of each conference / workshop
extract_ordinals <- function(names_list) {
# Regular expression pattern to match ordinal numbers up to "30th"
ordinal_pattern <- "\\b(?:[1-9]1?st|[1-9]2?nd|[1-9]3?rd|[4-9][0-9]?th|(1[0-9]|2[0-9]|3[0-9]|99)th|First|Second|Third|Fourth|Fifth|Sixth|Seventh|Eighth|Ninth|Tenth|Eleventh|Twelfth|Thirteenth|Fourteenth|Fifteenth|Sixteenth|Seventeenth|Eighteenth|Nineteenth|Twentieth|Twenty-first|Twenty-second|Twenty-third|Twenty-fourth|Twenty-fifth|Twenty-sixth|Twenty-seventh|Twenty-eighth|Twenty-ninth|Thirtieth|Thirty-first|Thirty-second|Thirty-third|Thirty-fourth|Thirty-fifth|Thirty-sixth|Thirty-seventh|Thirty-eighth|Thirty-ninth|Fortieth|Forty-first|Forty-second|Forty-third|Forty-fourth|Forty-fifth|Forty-sixth|Forty-seventh|Forty-eighth|Forty-ninth|Fiftieth|Fifty-first|Fifty-second|Fifty-third|Fifty-fourth|Fifty-fifth|Fifty-sixth|Fifty-seventh|Fifty-eighth|Fifty-ninth|Sixtieth|Sixty-first|Sixty-second|Sixty-third|Sixty-fourth|Sixty-fifth|Sixty-sixth|Sixty-seventh|Sixty-eighth|Sixty-ninth|Seventieth|Seventy-first|Seventy-second|Seventy-third|Seventy-fourth|Seventy-fifth|Seventy-sixth|Seventy-seventh|Seventy-eighth|Seventy-ninth|Eightieth|Eighty-first|Eighty-second|Eighty-third|Eighty-fourth|Eighty-fifth|Eighty-sixth|Eighty-seventh|Eighty-eighth|Eighty-ninth|Ninetieth|Ninety-first|Ninety-second|Ninety-third|Ninety-fourth|Ninety-fifth|Ninety-sixth|Ninety-seventh|Ninety-eighth|Ninety-ninth)\\b"
# Extract ordinal numbers from each entry
extracted_ordinals <- regmatches(names_list, gregexpr(ordinal_pattern, names_list))
# Create a vector to store the EDITIONS results
result <- character(length(names_list))
# Loop through each entry to assign ordinal numbers or NA
for (i in seq_along(names_list)) {
if (length(extracted_ordinals[[i]]) == 1) {# if > 1, combination of conferences -> too dificult to detect
ordinal_text <- extracted_ordinals[[i]]
# Check if the ordinal text already follows the "...th" pattern
if (grepl("\\b(?:\\d+st|\\d+nd|\\d+rd|\\d+th)", ordinal_text)) {
result[i] <- ordinal_text
} else {
# Extract the numeric value from the ordinal text
numeric_value <- switch(ordinal_text,
"First" = 1,
"Second" = 2,
"Third" = 3,
"Fourth" = 4,
"Fifth" = 5,
"Sixth" = 6,
"Seventh" = 7,
"Eighth" = 8,
"Ninth" = 9,
"Tenth" = 10,
"Eleventh" = 11,
"Twelfth" = 12,
"Thirteenth" = 13,
"Fourteenth" = 14,
"Fifteenth" = 15,
"Sixteenth" = 16,
"Seventeenth" = 17,
"Eighteenth" = 18,
"Nineteenth" = 19,
"Twentieth" = 20,
"Twenty-first" = 21,
"Twenty-second" = 22,
"Twenty-third" = 23,
"Twenty-fourth" = 24,
"Twenty-fifth" = 25,
"Twenty-sixth" = 26,
"Twenty-seventh" = 27,
"Twenty-eighth" = 28,
"Twenty-ninth" = 29,
"Thirtieth" = 30,
"Thirty-first" = 31,
"Thirty-second" = 32,
"Thirty-third" = 33,
"Thirty-fourth" = 34,
"Thirty-fifth" = 35,
"Thirty-sixth" = 36,
"Thirty-seventh" = 37,
"Thirty-eighth" = 38,
"Thirty-ninth" = 39,
"Fortieth" = 40,
"Forty-first" = 41,
"Forty-second" = 42,
"Forty-third" = 43,
"Forty-fourth" = 44,
"Forty-fifth" = 45,
"Forty-sixth" = 46,
"Forty-seventh" = 47,
"Forty-eighth" = 48,
"Forty-ninth" = 49,
"Fiftieth" = 50,
"Fifty-first" = 51,
"Fifty-second" = 52,
"Fifty-third" = 53,
"Fifty-fourth" = 54,
"Fifty-fifth" = 55,
"Fifty-sixth" = 56,
"Fifty-seventh" = 57,
"Fifty-eighth" = 58,
"Fifty-ninth" = 59,
"Sixtieth" = 60,
"Sixty-first" = 61,
"Sixty-second" = 62,
"Sixty-third" = 63,
"Sixty-fourth" = 64,
"Sixty-fifth" = 65,
"Sixty-sixth" = 66,
"Sixty-seventh" = 67,
"Sixty-eighth" = 68,
"Sixty-ninth" = 69,
"Seventieth" = 70,
"Seventy-first" = 71,
"Seventy-second" = 72,
"Seventy-third" = 73,
"Seventy-fourth" = 74,
"Seventy-fifth" = 75,
"Seventy-sixth" = 76,
"Seventy-seventh" = 77,
"Seventy-eighth" = 78,
"Seventy-ninth" = 79,
"Eightieth" = 80,
"Eighty-first" = 81,
"Eighty-second" = 82,
"Eighty-third" = 83,
"Eighty-fourth" = 84,
"Eighty-fifth" = 85,
"Eighty-sixth" = 86,
"Eighty-seventh" = 87,
"Eighty-eighth" = 88,
"Eighty-ninth" = 89,
"Ninetieth" = 90,
"Ninety-first" = 91,
"Ninety-second" = 92,
"Ninety-third" = 93,
"Ninety-fourth" = 94,
"Ninety-fifth" = 95,
"Ninety-sixth" = 96,
"Ninety-seventh" = 97,
"Ninety-eighth" = 98,
"Ninety-ninth" = 99)
result[i] <- paste0(numeric_value, "th")
}
} else {
result[i] <- NA
}
}
return(result)
}
conference_edition <- extract_ordinals(conference_name)
#table(conference_edition)
names(dblp_proceedings)
unique(dblp_proceedings$booktitle.string)
# Chunk 28
left_join_df <- left_join(Node_paper, conference_df, by = c("crossref.string.."="ref"))
# Chunk 1
library(skimr)
library(ggplot2)
library(tidyverse)
library(dplyr)
library(stringi)
library(devtools)
# Chunk 2
getwd()
setwd("/Users/ali/Downloads/dblp-to-csv-master")
#setwd("/Users/marcforto14/Desktop/dblp-to-csv-master")
# Chunk 3
dblp_article<-read.csv("dblp_article.csv",sep=";",row.names =NULL, fileEncoding = "UTF-8",nrows=1000) # load
dblp_article_header<-read.csv("dblp_article_header.csv",sep=";",row.names =NULL, fileEncoding = "UTF-8") # load header
colnames(dblp_article)<-names(dblp_article_header) # put the header
# Chunk 4
names(dblp_article)
dblp_article$article.ID # id
dblp_article$author.string.. # string de autors
dblp_article$ee.string.. # doi number
dblp_article$pages.string # !!abanico de pages, no num of pages
dblp_article$volume.string
dblp_article$title.string
# Chunk 5
compute_pages <- function(page_range) {
pages <- as.integer(unlist(strsplit(page_range, "-")))
if (length(pages) == 1) {
return(1)
} else {
return(pages[2] - pages[1] + 1)
}
}
total_pages <- 0*c(1:nrow(dblp_article))
for (i in 1:nrow(dblp_article)) {
total_pages[i] <- compute_pages(dblp_article$pages.string[i])
}
#total_pages[999];dblp_article[999,24] #814-775 està bé
dblp_article$numpages<-total_pages
# Chunk 6
#filter columns
names(dblp_article)
dblp_article <- dblp_article[,c(1,2,13,16,30,34,35,36)]# id, author, doi, journal, pages, title, volume, year
# Chunk 7
split_authors <- strsplit(dblp_article$author.string.., "\\|") # split els authors
Edge_papers_author_1 <- data.frame(
id_paper = rep(dblp_article$article.ID, sapply(split_authors, length)),
author = unlist(split_authors)
)
# if its the first author -> main
mark_main_author <- function(group) {
first_author <- group$author[1]
group$main_author <- ifelse(startsWith(group$author, first_author), TRUE, FALSE)
return(group)
}
Edge_papers_author_1 <- Edge_papers_author_1 %>%
group_by(id_paper) %>%
do(mark_main_author(.))
# Chunk 8
Node_authors_1 <- unique(Edge_papers_author_1[,2])  # save authors names
# Chunk 9
generate_abstract <- function() {
lorem_ipsum <- stri_rand_lipsum(1)  # Generate random Lorem Ipsum text
return(lorem_ipsum)
}
dblp_article$abstract <- sapply(dblp_article$article.ID, function(x) generate_abstract())
# Chunk 10
names(dblp_article)
Node_papers_1<- data.frame(
id_paper=dblp_article$article.ID,
paper_title=dblp_article$title.string,
doi = dblp_article$ee.string..,
abstract = dblp_article$abstract
)
Node_papers_1
# Chunk 11
Edge_paper_volumes <- data.frame(
id_paper = dblp_article$article.ID,
id_volume = paste(dblp_article$volume.string, dblp_article$journal.string, sep = " "),
volume = dblp_article$volume.string
)
write.csv(Edge_paper_volumes, "Edge_paper_volumes.csv", row.names = FALSE)
# Chunk 12
Node_volume <- data.frame(
volume =unique(Edge_paper_volumes$id_volume)
)
write.csv(Node_volume, "Node_volume.csv", row.names = FALSE)
names(Node_volumes)
# Chunk 13
Edge_paper_journal <- data.frame(
id_paper = dblp_article$article.ID,
journal = dblp_article$journal.string
)
Edge_paper_journal
write.csv(Edge_paper_journal, "Edge_paper_journal.csv", row.names = FALSE)
# Chunk 14
Node_journals <- unique(Edge_paper_journal[,2])
write.csv(Node_journals, "Node_journals.csv", row.names = FALSE)
# Chunk 15
Node_volumes<-unique(dblp_article$volume.string)
write.csv(Node_volumes, "Node_volumes.csv", row.names = FALSE)
# Chunk 16
dblp_inproceedings<-read.csv("dblp_inproceedings.csv",sep=";",row.names =NULL, fileEncoding = "UTF-8",nrows=1000)
dblp_inproceedings_header<-read.csv("dblp_inproceedings_header.csv",sep=";",row.names =NULL, fileEncoding = "UTF-8")
colnames(dblp_inproceedings)<-names(dblp_inproceedings_header)
# Chunk 17
total_pages <- 0*c(1:nrow(dblp_inproceedings))
for (i in 1:nrow(dblp_inproceedings)) {
total_pages[i] <- compute_pages(dblp_inproceedings$pages.string[i])
}
total_pages
dblp_inproceedings$numpages<-total_pages
# Chunk 18
dblp_inproceedings$abstract <- sapply(dblp_inproceedings$inproceedings.ID, function(x) generate_abstract())
# Chunk 19
# explore
names(dblp_inproceedings)
dblp_inproceedings$author.string.. #author
dblp_inproceedings$title.string # titul dels papers
dblp_inproceedings$crossref.string.. # key
dblp_inproceedings$inproceedings.ID # id dels papers
# Chunk 20
split_authors <- strsplit(dblp_inproceedings$author.string.., "\\|") # split els authors
Edge_papers_author_2 <- data.frame(
id_paper = rep(dblp_inproceedings$inproceedings.ID, sapply(split_authors, length)),
author = unlist(split_authors)
)
Edge_papers_author_2 <- unique(Edge_papers_author_2) # remove duplicate rows (id_paper, author)
# if its the first author -> main
mark_main_author <- function(group) {
first_author <- group$author[1]
group$main_author <- ifelse(startsWith(group$author, first_author), TRUE, FALSE)
return(group)
}
Edge_papers_author_2 <- Edge_papers_author_2 %>%
group_by(id_paper) %>%
do(mark_main_author(.))
# Chunk 21
Node_authors_2 <- unique(Edge_papers_author_2[,2])  # save only unique authors names
# Chunk 22
Node_papers_2<- data.frame(
id_paper=dblp_inproceedings$inproceedings.ID,
paper_title=dblp_inproceedings$title.string,
doi = dblp_inproceedings$ee.string..,
abstract = dblp_inproceedings$abstract
)
# Chunk 23
# Combine the two data frames using rbind
Node_paper <- rbind(Node_papers_1, Node_papers_2)
Node_paper
names(Node_paper)
Node_author <- rbind(Node_authors_1, Node_authors_2)
Node_author <- unique(Node_author)
Node_author
skim(Node_author)
Edge_papers_author <- rbind(Edge_papers_author_1, Edge_papers_author_2)
write.csv(Node_paper, "Node_paper.csv", row.names = FALSE) # df papers (node)
write.csv(Node_author, "Node_author.csv", row.names = FALSE) # df authors (node)
write.csv(Edge_papers_author, "Edge_papers_author.csv", row.names = FALSE) # df authors papers (relation)
# Chunk 24
dblp_proceedings<-read.csv("dblp_proceedings.csv",sep=";",row.names =NULL, encoding = "latin1",nrows=100000)
dblp_proceedings_header<-read.csv("dblp_proceedings_header.csv",sep=";",row.names =NULL, encoding = "latin1")
colnames(dblp_proceedings)<-names(dblp_proceedings_header)
# Chunk 25
#explore
colnames(dblp_proceedings)
dblp_proceedings$title.string # conference / workshop complete
dblp_proceedings$booktitle.string # conference / workshop name
dblp_proceedings$key.string # key
# Chunk 26
conference_split <- strsplit(dblp_proceedings$title.string, ", ")
conference_split[[945]] # example of entry
conference_name <- sapply(conference_split, function(x) paste(x[1], collapse = ", "))
detect_location <- function(entry) {
location <- entry[nchar(entry) < 20 & !grepl("\\d", entry)] # Select entries shorter than 20 characters and without any number
location <- paste(location, collapse = ", ") # Combine into a single string
return(location)
}
locations <- sapply(conference_split, detect_location)
conference_title <- sub(".*?((?:Conference|Workshop).*?$)", "\\1", conference_name)
# Chunk 27
# Extract the edition of each conference / workshop
extract_ordinals <- function(names_list) {
# Regular expression pattern to match ordinal numbers up to "30th"
ordinal_pattern <- "\\b(?:[1-9]1?st|[1-9]2?nd|[1-9]3?rd|[4-9][0-9]?th|(1[0-9]|2[0-9]|3[0-9]|99)th|First|Second|Third|Fourth|Fifth|Sixth|Seventh|Eighth|Ninth|Tenth|Eleventh|Twelfth|Thirteenth|Fourteenth|Fifteenth|Sixteenth|Seventeenth|Eighteenth|Nineteenth|Twentieth|Twenty-first|Twenty-second|Twenty-third|Twenty-fourth|Twenty-fifth|Twenty-sixth|Twenty-seventh|Twenty-eighth|Twenty-ninth|Thirtieth|Thirty-first|Thirty-second|Thirty-third|Thirty-fourth|Thirty-fifth|Thirty-sixth|Thirty-seventh|Thirty-eighth|Thirty-ninth|Fortieth|Forty-first|Forty-second|Forty-third|Forty-fourth|Forty-fifth|Forty-sixth|Forty-seventh|Forty-eighth|Forty-ninth|Fiftieth|Fifty-first|Fifty-second|Fifty-third|Fifty-fourth|Fifty-fifth|Fifty-sixth|Fifty-seventh|Fifty-eighth|Fifty-ninth|Sixtieth|Sixty-first|Sixty-second|Sixty-third|Sixty-fourth|Sixty-fifth|Sixty-sixth|Sixty-seventh|Sixty-eighth|Sixty-ninth|Seventieth|Seventy-first|Seventy-second|Seventy-third|Seventy-fourth|Seventy-fifth|Seventy-sixth|Seventy-seventh|Seventy-eighth|Seventy-ninth|Eightieth|Eighty-first|Eighty-second|Eighty-third|Eighty-fourth|Eighty-fifth|Eighty-sixth|Eighty-seventh|Eighty-eighth|Eighty-ninth|Ninetieth|Ninety-first|Ninety-second|Ninety-third|Ninety-fourth|Ninety-fifth|Ninety-sixth|Ninety-seventh|Ninety-eighth|Ninety-ninth)\\b"
# Extract ordinal numbers from each entry
extracted_ordinals <- regmatches(names_list, gregexpr(ordinal_pattern, names_list))
# Create a vector to store the EDITIONS results
result <- character(length(names_list))
# Loop through each entry to assign ordinal numbers or NA
for (i in seq_along(names_list)) {
if (length(extracted_ordinals[[i]]) == 1) {# if > 1, combination of conferences -> too dificult to detect
ordinal_text <- extracted_ordinals[[i]]
# Check if the ordinal text already follows the "...th" pattern
if (grepl("\\b(?:\\d+st|\\d+nd|\\d+rd|\\d+th)", ordinal_text)) {
result[i] <- ordinal_text
} else {
# Extract the numeric value from the ordinal text
numeric_value <- switch(ordinal_text,
"First" = 1,
"Second" = 2,
"Third" = 3,
"Fourth" = 4,
"Fifth" = 5,
"Sixth" = 6,
"Seventh" = 7,
"Eighth" = 8,
"Ninth" = 9,
"Tenth" = 10,
"Eleventh" = 11,
"Twelfth" = 12,
"Thirteenth" = 13,
"Fourteenth" = 14,
"Fifteenth" = 15,
"Sixteenth" = 16,
"Seventeenth" = 17,
"Eighteenth" = 18,
"Nineteenth" = 19,
"Twentieth" = 20,
"Twenty-first" = 21,
"Twenty-second" = 22,
"Twenty-third" = 23,
"Twenty-fourth" = 24,
"Twenty-fifth" = 25,
"Twenty-sixth" = 26,
"Twenty-seventh" = 27,
"Twenty-eighth" = 28,
"Twenty-ninth" = 29,
"Thirtieth" = 30,
"Thirty-first" = 31,
"Thirty-second" = 32,
"Thirty-third" = 33,
"Thirty-fourth" = 34,
"Thirty-fifth" = 35,
"Thirty-sixth" = 36,
"Thirty-seventh" = 37,
"Thirty-eighth" = 38,
"Thirty-ninth" = 39,
"Fortieth" = 40,
"Forty-first" = 41,
"Forty-second" = 42,
"Forty-third" = 43,
"Forty-fourth" = 44,
"Forty-fifth" = 45,
"Forty-sixth" = 46,
"Forty-seventh" = 47,
"Forty-eighth" = 48,
"Forty-ninth" = 49,
"Fiftieth" = 50,
"Fifty-first" = 51,
"Fifty-second" = 52,
"Fifty-third" = 53,
"Fifty-fourth" = 54,
"Fifty-fifth" = 55,
"Fifty-sixth" = 56,
"Fifty-seventh" = 57,
"Fifty-eighth" = 58,
"Fifty-ninth" = 59,
"Sixtieth" = 60,
"Sixty-first" = 61,
"Sixty-second" = 62,
"Sixty-third" = 63,
"Sixty-fourth" = 64,
"Sixty-fifth" = 65,
"Sixty-sixth" = 66,
"Sixty-seventh" = 67,
"Sixty-eighth" = 68,
"Sixty-ninth" = 69,
"Seventieth" = 70,
"Seventy-first" = 71,
"Seventy-second" = 72,
"Seventy-third" = 73,
"Seventy-fourth" = 74,
"Seventy-fifth" = 75,
"Seventy-sixth" = 76,
"Seventy-seventh" = 77,
"Seventy-eighth" = 78,
"Seventy-ninth" = 79,
"Eightieth" = 80,
"Eighty-first" = 81,
"Eighty-second" = 82,
"Eighty-third" = 83,
"Eighty-fourth" = 84,
"Eighty-fifth" = 85,
"Eighty-sixth" = 86,
"Eighty-seventh" = 87,
"Eighty-eighth" = 88,
"Eighty-ninth" = 89,
"Ninetieth" = 90,
"Ninety-first" = 91,
"Ninety-second" = 92,
"Ninety-third" = 93,
"Ninety-fourth" = 94,
"Ninety-fifth" = 95,
"Ninety-sixth" = 96,
"Ninety-seventh" = 97,
"Ninety-eighth" = 98,
"Ninety-ninth" = 99)
result[i] <- paste0(numeric_value, "th")
}
} else {
result[i] <- NA
}
}
return(result)
}
conference_edition <- extract_ordinals(conference_name)
#table(conference_edition)
names(dblp_proceedings)
unique(dblp_proceedings$booktitle.string)
# Chunk 28
#left_join_df <- left_join(Node_paper, conference_df, by = c("crossref.string.."="ref"))
names(Edge_papers_edition)
unique(Edge_papers_edition$ref_conf)
# Chunk 29
Node_edition_try <- data.frame(
ref_edition=dblp_proceedings$key.string,
edition_complete=dblp_proceedings$title.string,
acronym=dblp_proceedings$booktitle.string, #acronym conference
conference_name=conference_name,
conference_title = conference_title,
conference_edition=conference_edition,
location = locations,
year=dblp_proceedings$year.int
)
Node_edition<- data.frame(
ref_edition=dblp_proceedings$key.string,
edition=dblp_proceedings$title.string,
edition_num=conference_edition,
location = locations,
year=dblp_proceedings$year.int
)
write.csv(Node_edition, "Node_edition.csv", row.names = FALSE)
names(Node_edition)
# Chunk 30
Edge_edition_conference<- data.frame(
ref_edition=dblp_proceedings$key.string,
conference=dblp_proceedings$booktitle.string #acronym conference
)
write.csv(Edge_edition_conference, "Edge_edition_conference.csv", row.names = FALSE)
# Chunk 31
Node_conference<- data.frame(
unique(dblp_proceedings$booktitle.string)
)
Node_conference
write.csv(Node_conference, "Node_conference.csv", row.names = FALSE)
# Chunk 32
Edge_papers_edition<- data.frame(
id_paper=dblp_inproceedings$inproceedings.ID,
ref_edition=dblp_inproceedings$crossref.string..
)
write.csv(Edge_papers_edition, "Edge_papers_edition.csv", row.names = FALSE)
# Chunk 33
setwd("/Users/ali/Desktop/MASTER/Semestre 2/SDM/lab/PropertyGraph/Sense nom/PropertyGraphs_SDM/data")
dblp_topics<-read.csv("data_topics.csv",row.names =NULL, encoding = "latin1",header=TRUE)
# Chunk 34
names(dblp_topics)
Edge_papers_keywords<-dblp_topics[,c(1,3:5)]
# Chunk 35
Node_keywords <- unique(Edge_papers_keywords[,2])
Node_keywords
nsoe <- pivot_longer(Edge_papers_keywords, cols = -id_paper, values_to = "keywords")
# Chunk 36
Edge_keywords<-nsoe[,c(1,3)]
Edge_keywords
